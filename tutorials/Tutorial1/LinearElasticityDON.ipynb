{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fafaef8-c3b4-4367-9ff2-79204e7c55a0",
   "metadata": {},
   "source": [
    "# $L^2_\\mu$ and $H^1_\\mu$ training of DeepONet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17960190-522a-4304-b1a1-f18201b33cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIT License\n",
    "# Copyright (c) 2025\n",
    "#\n",
    "# This is part of the dino_tutorial package\n",
    "# \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND.\n",
    "# For additional questions contact Thomas O'Leary-Roseberry\n",
    "\n",
    "import os, sys\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('../../')\n",
    "\n",
    "from dinotorch_lite import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201ce7bc-67b4-4eed-8a71-813aaac5d9ff",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2c8390-ddb7-45fb-b3e6-33c0797ea984",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/full_state/'\n",
    "\n",
    "mq_data_dict = np.load(data_dir+'mq_data.npz')\n",
    "\n",
    "q_data = mq_data_dict['q_data']\n",
    "m_data = mq_data_dict['m_data']\n",
    "\n",
    "\n",
    "# fno_metadata = np.load(data_dir+'fno_metadata.npz')\n",
    "\n",
    "# d2v = fno_metadata['d2v_param']\n",
    "# v2d = fno_metadata['v2d_param']\n",
    "# nx = fno_metadata['nx']\n",
    "# ny = fno_metadata['ny']\n",
    "\n",
    "n_data, dQ = q_data.shape\n",
    "n_data, dM = m_data.shape\n",
    "\n",
    "print('dQ = ',dQ,', dM = ',dM)\n",
    "\n",
    "m_train = torch.Tensor(m_data[:-800])\n",
    "q_train = torch.Tensor(q_data[:-800])\n",
    "\n",
    "m_test = torch.Tensor(m_data[-200:])\n",
    "q_test = torch.Tensor(q_data[-200:])\n",
    "\n",
    "\n",
    "\n",
    "# Set up datasets and loaders\n",
    "l2train = L2Dataset(m_train,q_train)\n",
    "l2test = L2Dataset(m_test,q_test)\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(l2train, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(l2test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02ff4af-92ac-4a90-89d3-cae03b933d11",
   "metadata": {},
   "source": [
    "## $L^2_\\mu$ training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb2c5dc-15e4-417b-a525-ce425a09fb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_settings = fno2d_settings(modes1=4, modes2=4, width=64, n_layers=4, d_out=2)\n",
    "# model = VectorFNO2D(v2d=[d2v, d2v], d2v=[v2d, v2d], nx=nx, ny=ny, dim=2, settings=model_settings).to(device) \n",
    "\n",
    "rQ = 100\n",
    "\n",
    "model = DeepONetNodal(dM,dQ,rQ)\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "loss_func = normalized_f_mse\n",
    "# from scipy.sparse import csr_matrix, save_npz, load_npz\n",
    "# M_output = load_npz(data_dir+'M_output_csr.npz')\n",
    "# M_torch = scipy_csr_to_torch_csr(M_output).to(torch.float32) \n",
    "# M_torch.to(device)\n",
    "# loss_func = weighted_l2_norm(M_torch)\n",
    "\n",
    "lr_scheduler = None\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "network, history = l2_training(model,loss_func,train_loader, validation_loader,\\\n",
    "                     optimizer,lr_scheduler=lr_scheduler,n_epochs = n_epochs,verbose = True)\n",
    "\n",
    "rel_error = evaluate_l2_error(model,validation_loader,error_func = loss_func)\n",
    "\n",
    "print('L2 relative error = ', rel_error)\n",
    "\n",
    "torch.save(model.state_dict(), data_dir+'l2_model_don.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1ed5e3-8583-4845-beba-95ebe1163427",
   "metadata": {},
   "source": [
    "# $H^1_\\mu$ training of DON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940d3631-abb4-4d40-9ceb-705fed869fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional data\n",
    "rQ = 100\n",
    "\n",
    "J_data_dict = np.load(data_dir+'JstarPhi_data.npz',allow_pickle=True)\n",
    "J_data = J_data_dict['JstarPhi_data'].transpose((0,2,1))[:,:rQ,:]\n",
    "POD_encoder = np.load(data_dir+'POD/POD_encoder.npy')[:,:rQ]\n",
    "# POD_encoder = J_data_dict['MPhi'][:,:rQ]\n",
    "# POD_encoder.shape\n",
    "POD_encoder = torch.Tensor(POD_encoder).to(torch.float32)\n",
    "J_train = torch.Tensor(J_data[:-800])\n",
    "J_test = torch.Tensor(J_data[-200:])\n",
    "\n",
    "# Set up datasets and loaders\n",
    "dinotrain = DINODataset(m_train,q_train, J_train)\n",
    "dinotest = DINODataset(m_test,q_test, J_test)\n",
    "batch_size = 32\n",
    "\n",
    "dino_train_loader = DataLoader(dinotrain,  batch_size=batch_size, shuffle=True)\n",
    "dino_validation_loader = DataLoader(dinotest, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e928b1-8d0d-4808-a87b-632a14bbc4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepONetNodal(dM,dQ,rQ)\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "loss_func = normalized_f_mse\n",
    "loss_func_jac = normalized_f_mse\n",
    "\n",
    "lr_scheduler = None\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "network, history = h1_training(model,loss_func,loss_func_jac, dino_train_loader, dino_validation_loader,\\\n",
    "                     optimizer,lr_scheduler=lr_scheduler,n_epochs = n_epochs,verbose = True,\\\n",
    "                               output_projector = POD_encoder)\n",
    "\n",
    "rel_error = evaluate_l2_error(model,validation_loader,error_func = loss_func)\n",
    "\n",
    "print('L2 relative error = ', rel_error)\n",
    "\n",
    "torch.save(model.state_dict(), data_dir+'h1_model_don.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7137b8-e626-4cd7-bb82-6bf8ac7613fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
